{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml-project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": true,
    "toc-showtags": false,
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozwRm2-O_9Xt"
      },
      "source": [
        "# ARCHIVE\n",
        "\n",
        "> For WIP stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJpYiOhhdInB"
      },
      "source": [
        "# train_encoded[\"maxCount\"] = train_encoded.basket.map(lambda x: sum(x))\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlFrgY63Ukyn"
      },
      "source": [
        "#### 5.0 Feature 0: Am Meisten vorkommende Kategorie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tvry42WUkyn"
      },
      "source": [
        "# f_eng_basket = list(train_encoded.basket) # basket shortcut\n",
        "\n",
        "# 1. H√∂chste Kategorie aktuellem Basket finden\n",
        "# train_encoded[\"maxCount\"] = train_encoded.basket.map(lambda x: max(x))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgz22gJ1a8ww"
      },
      "source": [
        "#### 5.0 Feature 0: Anzahl der B√ºcher von der am h√∂chsten vorkommenden Kategorie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIW3ajYua8wx"
      },
      "source": [
        "# f_eng_basket = list(train_encoded.basket) # basket shortcut\n",
        "\n",
        "# 1. H√∂chste Kategorie aktuellem Basket finden\n",
        "# maxBasketValues = list(train_encoded.basket.map(lambda x: max(x)))\n",
        "\n",
        "# 2. Diese Z√§hlen & als Neues Feature einf√ºgen\n",
        "# train_encoded['maxCount'] = [basket.count(maxBasketValues[i]) for (i, basket) in enumerate(f_eng_basket) ]\n",
        "\n",
        "# train_encoded.head()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eXwOIuXUkyn"
      },
      "source": [
        "#### 5.1 Feature 1: Bestellungen, die √ºberdurschnittlich viele B√ºcher im Warenkorb haben\n",
        "\n",
        "> Feature erstellen, dass positiv ist wenn die Anzahl an B√ºchern im Warenkorb √ºber dem Median liegt\n",
        "\n",
        "1. √úberdurschnittliche Anzahl B√ºcher: '1'\n",
        "1. Unterdurschnittliche Anzahl B√ºcher: '0'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCG_bKNpUkyn"
      },
      "source": [
        "# TODO after & before test -> It does not really pay of ?\n",
        "\n",
        "#from statistics import median\n",
        "#\n",
        "## TODO visualize, whether returned & above median\n",
        "## Visualize relationship between number items in basket and return feature\n",
        "#\n",
        "## Calculate median from the number of items in each basket\n",
        "#train_encoded['basketSizeMedian'] = median([len(basket) for basket in train_encoded['basket']])\n",
        "#train_encoded[['returnLabel', 'basketElementCount', 'basketSizeMedian']].head(n=20)\n",
        "#\n",
        "#returnedAboveMedian = []\n",
        "#\n",
        "#for index, row in train_encoded.iterrows():\n",
        "#     returnedAboveMedian.append(1 if (row['returnLabel'] == 0 and row['basketElementCount'] >= row['basketSizeMedian']) else 0)\n",
        "#         \n",
        "#train_encoded['returnedAboveMedian'] = returnedAboveMedian\n",
        "#\n",
        "#train_encoded['returnedAboveMedian'].value_counts()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBd6-BKtUkyM"
      },
      "source": [
        "### 0. Helpers\n",
        "\n",
        "> Helper functions used in upcoming sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZaK73TuUkya"
      },
      "source": [
        "import os \n",
        "import re # RegEx\n",
        "\n",
        "# Tiny print helpers:\n",
        "    \n",
        "# Print the statement centered  ¬Ø\\_(„ÉÑ)_/¬Ø \n",
        "centeredPrint = lambda statement: print(statement.center(os.get_terminal_size().columns))\n",
        "# Get Separator line to match whole statement length. F.ex: text -> ----\n",
        "getSeparator = lambda text: len(text)*\"-\" # table Top/Bottom separators\n",
        "\n",
        "\"\"\"\n",
        "Convert's a string list into a regular list:\n",
        "F.ex. [0, 1, 2, 3] from type **String** -> to type **Int**\n",
        "\n",
        "Let's deconstruct this:\n",
        "\n",
        "1. In the for loop: Convert the 'String' list into a regular list by:\n",
        "    * Remove the Square brackets\n",
        "    * Split the string into a list\n",
        "2. For each element in the created list convert it from string to int\n",
        "\n",
        "K√∂nnnen es gerne vereinfachen, wenn es w√§rend der Pr√§zi zu verwirrungen kommen k√∂nnte üòÖ\n",
        "\n",
        "\"\"\"\n",
        "getIntListFromStringList = lambda stringList: [int(listElement) for listElement in re.sub(\"[\\[\\]]\", \"\", stringList).split(',')]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBydEatRUkyc"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## TRAINING üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4JeW5-iUkyc"
      },
      "source": [
        "### 1. Laden Sie die Trainingsdaten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "WxUcfJUWUkyc",
        "outputId": "8e5ed4ca-8685-4414-afa6-cb4ea1e3c211"
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# train_df = pd.read_csv('datasets/train.csv')\n",
        "train_df = pd.read_csv('sample_data/train.csv')\n",
        "\n",
        "train_df.head(10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transactionId</th>\n",
              "      <th>basket</th>\n",
              "      <th>customerType</th>\n",
              "      <th>totalAmount</th>\n",
              "      <th>returnLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7934161612</td>\n",
              "      <td>[3]</td>\n",
              "      <td>existing</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5308629088</td>\n",
              "      <td>[5, 3, 0, 3]</td>\n",
              "      <td>existing</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1951363325</td>\n",
              "      <td>[3, 3, 1, 4]</td>\n",
              "      <td>new</td>\n",
              "      <td>308.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6713597713</td>\n",
              "      <td>[2]</td>\n",
              "      <td>existing</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8352683669</td>\n",
              "      <td>[4, 4, 4, 4]</td>\n",
              "      <td>new</td>\n",
              "      <td>324.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7416526871</td>\n",
              "      <td>[4, 3, 4, 4]</td>\n",
              "      <td>new</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5297184153</td>\n",
              "      <td>[3, 4]</td>\n",
              "      <td>existing</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5634650486</td>\n",
              "      <td>[4, 4, 1, 4, 4]</td>\n",
              "      <td>new</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5788331730</td>\n",
              "      <td>[1, 5, 2, 2]</td>\n",
              "      <td>existing</td>\n",
              "      <td>240.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7800645047</td>\n",
              "      <td>[5, 5, 0]</td>\n",
              "      <td>existing</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   transactionId           basket customerType  totalAmount  returnLabel\n",
              "0     7934161612              [3]     existing         77.0            0\n",
              "1     5308629088     [5, 3, 0, 3]     existing         64.0            0\n",
              "2     1951363325     [3, 3, 1, 4]          new        308.0            1\n",
              "3     6713597713              [2]     existing         74.0            0\n",
              "4     8352683669     [4, 4, 4, 4]          new        324.0            1\n",
              "5     7416526871     [4, 3, 4, 4]          new        256.0            1\n",
              "6     5297184153           [3, 4]     existing        110.0            1\n",
              "7     5634650486  [4, 4, 1, 4, 4]          new        100.0            1\n",
              "8     5788331730     [1, 5, 2, 2]     existing        240.0            0\n",
              "9     7800645047        [5, 5, 0]     existing        138.0            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-lKsxU4Ukyd"
      },
      "source": [
        "### 2. F√ºllen Sie die fehlenden Werte in den Trainingsdaten auf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kxjXQ5vUkye"
      },
      "source": [
        "#### 2.1 Analysis of missing data\n",
        "\n",
        "> Analyze which data is missing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFPViJQ0Ukye",
        "scrolled": true,
        "outputId": "2f72841d-efd4-4d66-fd6b-7053a57ddfcc"
      },
      "source": [
        "# Analysis of missing data\n",
        "\n",
        "heading = \"Total number of missing training values:\"\n",
        "\n",
        "print(getSeparator(heading))\n",
        "print(heading)\n",
        "print(train_df.isnull().sum()) # Check which values are null\n",
        "print(getSeparator(heading))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Total number of missing training values:\n",
            "transactionId      0\n",
            "basket             0\n",
            "customerType     517\n",
            "totalAmount      484\n",
            "returnLabel        0\n",
            "dtype: int64\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-tM86jVUkyf"
      },
      "source": [
        "The missing `customerType` data is of categorical value(`existing` or `new`).  \n",
        "\n",
        "In the following, let's check whether it's worthwhile to replace missing values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk5u1XaPUkyf",
        "scrolled": true,
        "outputId": "aca5db93-4cdf-4e06-bf57-f5f5e9352440"
      },
      "source": [
        "# Calculate the percentage of the cases where the customer type is null\n",
        "# Use this value to decide, whether this values can be \"safely\" removed\n",
        "\n",
        "customerDataSum = train_df[\"customerType\"].count()\n",
        "missingCustomerTypeData = train_df[\"customerType\"].isnull().sum()\n",
        "\n",
        "# Calaculated values\n",
        "customerType_isNull_percentage = round(missingCustomerTypeData * 100 / customerDataSum, 2)\n",
        "missing_customerType_amount = round(customerDataSum*(customerType_isNull_percentage/100))\n",
        "\n",
        "print(f'\\nThe percentage of missing values in the {customerDataSum} big CustomerType dataset is only {str(customerType_isNull_percentage).replace(\".\", \",\")} % = {str(missing_customerType_amount)} missing values')\n",
        "print('==> Removing missing values should not have a big impact on the resulting model!')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The percentage of missing values in the 24483 big CustomerType dataset is only 2,11 % = 517 missing values\n",
            "==> Removing missing values should not have a big impact on the resulting model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf24vNC8Ukyg"
      },
      "source": [
        "#### 2.2 Actual  filling/removing of data\n",
        "\n",
        "1. Remove missing `customerType` values\n",
        "2. Fill na's with mean for `totalAmount` feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSsUbWYLUkyg",
        "scrolled": true,
        "outputId": "20ad5f25-deab-4001-e42c-722bc419e93f"
      },
      "source": [
        "# TODO maybe as external function due to test code duplication?\n",
        "\n",
        "# Drop customerType NaN' s -> See decision why above\n",
        "train_cleaned = train_df[train_df['customerType'].notna()]\n",
        "\n",
        "# Total amount: Fill with mean's\n",
        "totalAmount_mean = train_cleaned['totalAmount'].mean()\n",
        "train_cleaned['totalAmount'].fillna(totalAmount_mean, inplace=True)\n",
        "\n",
        "print(f'Total number of missing training values after cleaning up: {train_cleaned.isnull().sum().sum()}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of missing training values after cleaning up: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaXqZk6WUkyg"
      },
      "source": [
        "### 3. Transformieren Sie die kategorischen Features mittles One-hot-encoding\n",
        "\n",
        "1. Find categorical features\n",
        "2. One-Hot Encode categorical features found in step 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3XrfozEUkyh"
      },
      "source": [
        "#### 3.1 Get a list/Find out categorical columns\n",
        "\n",
        "> As seen in: https://stackoverflow.com/questions/29803093/check-which-columns-in-dataframe-are-categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZMlsKA-Ukyh",
        "outputId": "6566d624-0a0f-4027-eb20-544e3af054c2"
      },
      "source": [
        "columns = train_cleaned.columns\n",
        "\n",
        "# Columns with numerical data\n",
        "num_cols = train_cleaned._get_numeric_data().columns\n",
        "\n",
        "# Now Substract all columns from the numerical ones\n",
        "categorical_columns = list(set(columns) - set(num_cols))\n",
        "\n",
        "print(\"Categorical attributes found: \", *categorical_columns, sep=\"\\n* \")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical attributes found: \n",
            "* customerType\n",
            "* basket\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiCyJX-8Ukyh"
      },
      "source": [
        "#### 3.2 Hot encode customer type\n",
        "\n",
        "> Use pandas build in function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_pU_UYHUkyi"
      },
      "source": [
        "one_hot_customerType = pd.get_dummies(train_cleaned['customerType'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tdv56jOmUkyi",
        "outputId": "0afa45f9-c608-444e-bec9-b634a0ed5f19"
      },
      "source": [
        "# TODO fix Inappropriate ioctl for device\n",
        "# centeredPrint('One hot encoding for the customer type:\\n\\n')\n",
        "print('One hot encoding for the customer type:\\n\\n')\n",
        "\n",
        "one_hot_customerType.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One hot encoding for the customer type:\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>existing</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   existing  new\n",
              "0         1    0\n",
              "1         1    0\n",
              "2         0    1\n",
              "3         1    0\n",
              "4         0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB696DtFUkyi"
      },
      "source": [
        "#### 3.3 Hot encode the basket values\n",
        "\n",
        "> We'll do this manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHv_FrQkUkyi"
      },
      "source": [
        "<hr>\n",
        "Get the max/min values in the basket feature lists\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xy1UyFTUkyj",
        "outputId": "7a7655d3-7be5-410f-b41e-cbccd794b152"
      },
      "source": [
        "# For each basket, get the min/max\n",
        "# Web get them as strings, therefore we use our helper function to convert them to int lists\n",
        "min_basket_value = min([min(getIntListFromStringList(list)) for list in train_cleaned['basket']]) \n",
        "max_basket_value = max([max(getIntListFromStringList(list)) for list in train_cleaned['basket']]) \n",
        "\n",
        "print(f'The minimal value basket element is {min_basket_value} and the max basket value is {max_basket_value}')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimal value basket element is 0 and the max basket value is 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll1euX0VUkyj"
      },
      "source": [
        "<hr>\n",
        "Create new features based on the elements in the basket:\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WaSX45MSUkyj",
        "outputId": "6795308a-b345-478b-eca2-0c92ed9e0f59"
      },
      "source": [
        "# NOTE: We assume, that we have all these values in the basket label array\n",
        "#       We did NOT test this! Maybe test this to have more security...\n",
        "# TODO check whether all values are actually in the list\n",
        "\n",
        "# List with basket elements\n",
        "basketElements = list(range(min_basket_value, max_basket_value+1))\n",
        "\n",
        "# Data frame with columns: 'b_0 | b_1 | ...' for each of our basket elements\n",
        "one_hot_basket = pd.DataFrame([], columns=[f'b_{basketElement}' for basketElement in basketElements])\n",
        "\n",
        "'''\n",
        "Do the one hot encoding for the basket feature.\n",
        "Actually just:\n",
        "    1. Check for the current basket, whether the element is present\n",
        "    2. If present, set the encoding bit\n",
        "'''\n",
        "for basketElement in basketElements:\n",
        "      one_hot_basket[f'b_{basketElement}'] = train_cleaned['basket'].apply(lambda x: x.count(str(basketElement)))\n",
        "\n",
        "one_hot_basket.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b_0</th>\n",
              "      <th>b_1</th>\n",
              "      <th>b_2</th>\n",
              "      <th>b_3</th>\n",
              "      <th>b_4</th>\n",
              "      <th>b_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   b_0  b_1  b_2  b_3  b_4  b_5\n",
              "0    0    0    0    1    0    0\n",
              "1    1    0    0    2    0    1\n",
              "2    0    1    0    2    1    0\n",
              "3    0    0    1    0    0    0\n",
              "4    0    0    0    0    4    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLXIStuYUkyk"
      },
      "source": [
        "#### 3.4 Concatenate it back into the original dataframe\n",
        "\n",
        "> Use pandas build in function\n",
        "\n",
        "1. Concatenate\n",
        "2. Clean up no more needed features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwDVOkxqUkyk"
      },
      "source": [
        "train_encoded = pd.concat([train_cleaned, one_hot_customerType, one_hot_basket], axis=1)\n",
        "\n",
        "# We'll keep basket, as it'll probably be helpful for the feature engineering, \n",
        "# We'll only convert it to an int list(from string) for better handling\n",
        "train_encoded['basket'] = [getIntListFromStringList(basket) for basket in train_cleaned.basket]\n",
        "\n",
        "# Clean up: Drop customerType as it is no longer needed\n",
        "train_encoded = train_encoded.drop(columns=['customerType'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu6ga6_KUkyl"
      },
      "source": [
        "### 4. Datenattribute eliminieren\n",
        "\n",
        "> Datenattribute die nicht mit Zielvariable korrelieren entfernen\n",
        "\n",
        "Zu entfernen:\n",
        "    \n",
        "1. `transactionId`    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "XOZiBl9uUkyl",
        "outputId": "7c9467bb-9254-4345-aa1e-3392943d61fd"
      },
      "source": [
        "# TODO better naming to dataframes\n",
        "train_encoded = train_encoded.drop(columns=['transactionId'])\n",
        "train_encoded.head(10)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>basket</th>\n",
              "      <th>totalAmount</th>\n",
              "      <th>returnLabel</th>\n",
              "      <th>existing</th>\n",
              "      <th>new</th>\n",
              "      <th>b_0</th>\n",
              "      <th>b_1</th>\n",
              "      <th>b_2</th>\n",
              "      <th>b_3</th>\n",
              "      <th>b_4</th>\n",
              "      <th>b_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[3]</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5, 3, 0, 3]</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[3, 3, 1, 4]</td>\n",
              "      <td>308.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2]</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[4, 4, 4, 4]</td>\n",
              "      <td>324.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[4, 3, 4, 4]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[3, 4]</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[4, 4, 1, 4, 4]</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[1, 5, 2, 2]</td>\n",
              "      <td>240.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[5, 5, 0]</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            basket  totalAmount  returnLabel  existing  ...  b_2  b_3  b_4  b_5\n",
              "0              [3]         77.0            0         1  ...    0    1    0    0\n",
              "1     [5, 3, 0, 3]         64.0            0         1  ...    0    2    0    1\n",
              "2     [3, 3, 1, 4]        308.0            1         0  ...    0    2    1    0\n",
              "3              [2]         74.0            0         1  ...    1    0    0    0\n",
              "4     [4, 4, 4, 4]        324.0            1         0  ...    0    0    4    0\n",
              "5     [4, 3, 4, 4]        256.0            1         0  ...    0    1    3    0\n",
              "6           [3, 4]        110.0            1         1  ...    0    1    1    0\n",
              "7  [4, 4, 1, 4, 4]        100.0            1         0  ...    0    0    4    0\n",
              "8     [1, 5, 2, 2]        240.0            0         1  ...    2    0    0    1\n",
              "9        [5, 5, 0]        138.0            0         1  ...    0    0    0    2\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB4_D1cpUkym"
      },
      "source": [
        "### 5. Versuchen Sie auf Basis des Attributs basket Features zu bauen (z.B. wie oft kommt jede Kategorie im Basket vor).\n",
        "\n",
        "> Gesucht: Features zur Hilfe der Vorhersage ob Kunde Bestellung zur√ºckschickt\n",
        "\n",
        "* Diagramme nutzen um bestehende Zusammenh√§nge zu visualisieren & aussagekr√§ftigere features zu entwerfen die mit dem Zielwert Korrelieren(Negativ oder Positv)\n",
        "\n",
        "From one hot encoding:\n",
        "\n",
        "- [x] Wie oft kommt jede Kategorie im Basket vor\n",
        "- [x] Neukunde oder bestehender\n",
        "\n",
        "Others:\n",
        "\n",
        "-> Not correlated\n",
        "\n",
        "- [x] Anzahl der bestellten Werte -> Not correlated(From slides)\n",
        "- [x] Number of books from the highest occurring category -> Not correlated\n",
        "- [x] Highest occurring category -> Not correlated\n",
        "- [x] Sum of categories -> Not correlated\n",
        "- [ ] High total amount & new customer\n",
        "- [ ] Number of highest occurring category in basket excedes the 70 % quantile\n",
        "- [ ] \n",
        "- [ ] \n",
        "\n",
        "Sources/Helpers:\n",
        "\n",
        "1. Uni docuements:\n",
        "\n",
        "* Theory:\n",
        "    - General overview: https://github.com/daniel-vera-g/ml-kurs/blob/master/7_ML-Projekt_Demo.ipynb\n",
        "    - Feature eng. overview: https://github.com/daniel-vera-g/ml-kurs/blob/master/3_Feature_Engineering.ipynb\n",
        "    - Feature eng. PDF: file:///home/dvg/Desktop/relevant-ml/ML_Ue3_Feature_Engineering_Loesung.pdf\n",
        "* Praxis:\n",
        "    - Sex feature: https://github.com/daniel-vera-g/ml-kurs/blob/master/self/A2-titanic-logistic-regression.ipynb -> Refer solution\n",
        "    - Embarked Feature: https://github.com/daniel-vera-g/ml-kurs/blob/master/3_Titanic_Dataset_Features.ipynb -> Refer Solution\n",
        "\n",
        "2. Ideas:\n",
        "\n",
        "> See: https://towardsdatascience.com/market-basket-analysis-with-pandas-246fb8ee10a5\n",
        "\n",
        "* Plot to show relation between huge amount in basket and return value\n",
        "* One common technique is association rule learning which is a machine learning method to discover relationships among variables. Apriori algorithm is a frequently used algorithm for association rule learning.\n",
        "* One way is to create combinations of items in each row and count the occurrences of each combination. The itertools of python can be used to accomplish this task.\n",
        "* Also: https://heartbeat.fritz.ai/a-practical-guide-to-feature-engineering-in-python-8326e40747c8\n",
        "* https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/04_features/a_features.ipynb\n",
        "\n",
        "TODO use diff. Diagramms & Plots to visualize features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKF-QfTZa8w-"
      },
      "source": [
        "#### 5.0 Feature 0: Am Meisten vorkommende Kategorie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "kRiremNfa8w_",
        "outputId": "1ccf4131-1848-422a-86ef-47f2608309ef"
      },
      "source": [
        "def all_same(items):\n",
        "    return all(x == items[0] for x in items)\n",
        "\n",
        "train_encoded['same'] = train_encoded.basket.map(lambda x: 1 if all_same(x)  else 0)\n",
        "\n",
        "# ---\n",
        "\n",
        "# Korrelation zwischen Anzahl gekaufter B√ºcher und dem Gesamtpreis den man daf√ºr bezahlt hat\n",
        "# TODO better naming\n",
        "\n",
        "# DOING!\n",
        "\n",
        "f_eng_basket = list(train_encoded.basket) # basket shortcut\n",
        "\n",
        "train_encoded['maxCount'] = [round(train_encoded.totalAmount.iloc[i]/sum(basket), 2) for (i, basket) in enumerate(f_eng_basket) ]\n",
        "train_encoded.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>basket</th>\n",
              "      <th>totalAmount</th>\n",
              "      <th>returnLabel</th>\n",
              "      <th>existing</th>\n",
              "      <th>new</th>\n",
              "      <th>b_0</th>\n",
              "      <th>b_1</th>\n",
              "      <th>b_2</th>\n",
              "      <th>b_3</th>\n",
              "      <th>b_4</th>\n",
              "      <th>b_5</th>\n",
              "      <th>same</th>\n",
              "      <th>maxCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[3]</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5, 3, 0, 3]</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[3, 3, 1, 4]</td>\n",
              "      <td>308.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2]</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>37.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[4, 4, 4, 4]</td>\n",
              "      <td>324.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         basket  totalAmount  returnLabel  existing  ...  b_4  b_5  same  maxCount\n",
              "0           [3]         77.0            0         1  ...    0    0     1     25.67\n",
              "1  [5, 3, 0, 3]         64.0            0         1  ...    0    1     0      5.82\n",
              "2  [3, 3, 1, 4]        308.0            1         0  ...    1    0     0     28.00\n",
              "3           [2]         74.0            0         1  ...    0    0     1     37.00\n",
              "4  [4, 4, 4, 4]        324.0            1         0  ...    4    0     1     20.25\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy_ks3VlUkyo"
      },
      "source": [
        "### 6. Skalieren Sie die Features mit einem StandardScaler.\n",
        "\n",
        "> Use sklearn scaler\n",
        "\n",
        "1. Drop target feature\n",
        "2. scale the x results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXEFQCUUkyo",
        "outputId": "d64d8d88-38cb-4c2f-9484-d0d04387b25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Drop basket feature after using it in the feature eng. phase\n",
        "train_encoded = train_encoded.drop(columns=['basket'])\n",
        "# Drop our target\n",
        "x = train_encoded.drop(columns=['returnLabel'])\n",
        "\n",
        "# Our x/y values\n",
        "X = scaler.fit_transform(x)\n",
        "y = train_encoded['returnLabel'].values"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-ffe62e2dcb47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Our x/y values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'returnLabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    698\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    699\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUfOH07XUkyo"
      },
      "source": [
        "### 7. Trainieren Sie die folgenden Klassifikationsmodelle und probieren Sie die angegebenen Hyperparameter mittels Cross-Validation aus:\n",
        "\n",
        "TODO understand all copied from: https://github.com/daniel-vera-g/ml-kurs/blob/master/7_ML-Projekt_Demo.ipynb\n",
        "\n",
        "For all models:\n",
        "\n",
        "1. Use grid search to find best parameter values\n",
        "2. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHP0OkMUkyp"
      },
      "source": [
        "# Helper func to find best params\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def findBestParams(model, params, X, y):\n",
        "    '''\n",
        "    Takes a model, possible parameters to test, X and y values.\n",
        "    Determines the best possible values for the model\n",
        "    and returns the best values.\n",
        "    '''\n",
        "     \n",
        "    clf = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1)\n",
        "    clf = clf.fit(X, y)\n",
        "    \n",
        "    # Get Params to extract from the estimator\n",
        "    paramKeys = list(params[0].keys()) # Get Param Names = Keys\n",
        "    paramsToDetermine = [f'clf.best_estimator_.{param}' for param in paramKeys] # Build strings\n",
        "    # evaluate str to actual estimator val(Yeeh, could be done above...but here more organised)\n",
        "    paramsToDetermine = [eval(param, {}, {\"clf\": clf}) for param in paramsToDetermine]\n",
        "    \n",
        "    print(f'Best {model} values: {paramsToDetermine}')\n",
        "    \n",
        "    return paramsToDetermine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXnPrvEFUkyp"
      },
      "source": [
        "#### 7.1 Logistische Regression: `C :[0.1,1,4,5,6,10,30,100]`und `penalty: [\"l1\", \"l2\"]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F73iGJCEUkyp"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# TODO Uncomment for testing\n",
        "\n",
        "lr_C, lr_penalty= findBestParams(model=LogisticRegression(), params=[{'C': [0.1,1,4,5,6,10,30,100], 'penalty': [\"l1\", \"l2\"]}], X=X, y=y)\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=0, penalty=lr_penalty ,C=lr_C)\n",
        "lr_model.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzLsOaEvUkyq"
      },
      "source": [
        "#### 7.2 Random Forest: `n_estimators: [60,80,100,120,140]` und `max_depth: [2, 3, 4, 5]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDRQQAizUkyq"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# TODO Uncomment for testing\n",
        "\n",
        "rf_n_est, rf_max_depth = findBestParams(model=RandomForestClassifier(), params=[{'n_estimators': [60,80,100,120,140], 'max_depth': [2, 3, 4, 5]}], X=X, y=y)\n",
        "rf_model = RandomForestClassifier(random_state=0, max_depth=rf_max_depth, n_estimators=rf_n_est)\n",
        "rf_model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMcJvMr3Ukyq"
      },
      "source": [
        "#### 7.3 Gradient Boosting Tree: gleiche Hyperparameter wie bei Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOIIEDwqUkyq"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# TODO Uncomment for testing\n",
        "\n",
        "gb_n_est, gb_max_depth = findBestParams(model=GradientBoostingClassifier(), params=[{'n_estimators': [60,80,100,120,140], 'max_depth': [2, 3, 4, 5]}], X=X, y=y)\n",
        "gb_model = GradientBoostingClassifier(random_state=0, max_depth=gb_max_depth, n_estimators=gb_n_est)\n",
        "gb_model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oPSZT6rUkyr"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## TESTING üß™\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiFtbSodUkyr"
      },
      "source": [
        "### 8. Laden der Testdaten\n",
        "\n",
        "> Bei den Testdaten ist der Vorgang nahezu der gleiche. Zur unterscheidbarkeit, wurde jeweils ein `test_[...]` prefix an die variablen gesetzt.\n",
        "\n",
        "* TODO Export functions to only call them once & avoid code duplication between train & test procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmFFVXpSUkyr"
      },
      "source": [
        "# test_df = pd.read_csv('datasets/test.csv')\n",
        "test_df = pd.read_csv('sample_data/test.csv')\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7iUzgz8Ukyr"
      },
      "source": [
        "### 9. Entfernen Sie alle Zeilen mit fehlenden Werten.\n",
        "\n",
        "1, Analysis of missing data  \n",
        "2. Remove missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZclmBxHnUkyr",
        "scrolled": true
      },
      "source": [
        "# Analysis of missing data\n",
        "\n",
        "# TODO remove this duplicated code into own function(Reduce code duplication!)\n",
        "\n",
        "test_heading = \"Total number of missing test values:\"\n",
        "\n",
        "print(getSeparator(test_heading))\n",
        "print(test_heading)\n",
        "print(test_df.isnull().sum()) # Check which values are null\n",
        "print(getSeparator(test_heading))\n",
        "\n",
        "# Calculate the percentage of the cases where the customer type is null\n",
        "# Use this value to decide, whether this values can be \"safely\" removed\n",
        "\n",
        "test_customerDataSum = test_df[\"customerType\"].count()\n",
        "test_missingCustomerTypeData = test_df[\"customerType\"].isnull().sum()\n",
        "\n",
        "# Calaculated values\n",
        "test_customerType_isNull_percentage = round(test_missingCustomerTypeData * 100 / test_customerDataSum, 2)\n",
        "test_missing_customerType_amount = round(test_customerDataSum*(test_customerType_isNull_percentage/100))\n",
        "\n",
        "print(f'\\nThe percentage of missing test values in the {test_customerDataSum} big CustomerType dataset is only {str(test_customerType_isNull_percentage).replace(\".\", \",\")} % = {str(test_missing_customerType_amount)} missing values')\n",
        "print('==> Removing missing values should not have a big impact!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4BEKfjwUkys",
        "scrolled": true
      },
      "source": [
        "# TODO maybe as external function due to test code duplication?\n",
        "# TODO ask/check whether filling would not be more effective/better\n",
        "# TODO if filling better, create function to reduce code duplication\n",
        "\n",
        "# Drop customerType NaN' s -> See decision why above\n",
        "test_cleaned = test_df[test_df['customerType'].notna()]\n",
        "\n",
        "# Total amount: Fill with mean's\n",
        "test_totalAmount_mean = test_cleaned['totalAmount'].mean()\n",
        "test_cleaned['totalAmount'].fillna(test_totalAmount_mean, inplace=True)\n",
        "\n",
        "print(f'Total number of missing test values after cleaning up: {test_cleaned.isnull().sum().sum()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3NhD3CKUkys"
      },
      "source": [
        "### 10. Transformieren Sie die kategorischen Features mittles One-hot-encoding\n",
        "\n",
        "1. Actually get categorical features\n",
        "2. One-Hot Encode categorical features from steps 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFL71fAgUkys"
      },
      "source": [
        "#### 10.1 Get a list/Find out categorical columns\n",
        "\n",
        "> As seen in: https://stackoverflow.com/questions/29803093/check-which-columns-in-dataframe-are-categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ropAb_fUkys"
      },
      "source": [
        "test_columns = test_cleaned.columns\n",
        "\n",
        "# Columns with numerical data\n",
        "test_num_cols = test_cleaned._get_numeric_data().columns\n",
        "\n",
        "# Now Substract all columns from the numerical ones\n",
        "test_categorical_columns = list(set(test_columns) - set(test_num_cols))\n",
        "\n",
        "print(\"Categorical test attributes found: \", *test_categorical_columns, sep=\"\\n* \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GTaf4rVUkys"
      },
      "source": [
        "#### 10.2 Hot encode customer type\n",
        "\n",
        "> Use pandas build in function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WefdMhmoUkyt"
      },
      "source": [
        "test_one_hot_customerType = pd.get_dummies(test_cleaned['customerType'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28vxayFVUkyt"
      },
      "source": [
        "# TODO fix Inappropriate ioctl for device\n",
        "# centeredPrint('One hot encoding for the customer type:\\n\\n')\n",
        "print('One hot encoding for the customer type:\\n\\n')\n",
        "\n",
        "test_one_hot_customerType.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e-uAV7eUkyt"
      },
      "source": [
        "#### 10.3 Hot encode the basket values\n",
        "\n",
        "> We'll do this manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puakdmbsUkyt"
      },
      "source": [
        "<hr>\n",
        "Get the max/min values in the basket feature lists\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyw6lAMyUkyt"
      },
      "source": [
        "# For each basket, get the min/max\n",
        "# Web get them as strings, therefore we use our helper function to convert them to int lists\n",
        "test_min_basket_value = min([min(getIntListFromStringList(list)) for list in test_cleaned['basket']]) \n",
        "test_max_basket_value = max([max(getIntListFromStringList(list)) for list in test_cleaned['basket']]) \n",
        "\n",
        "print(f'The minimal test value basket element is {test_min_basket_value} and the max basket value is {test_max_basket_value}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC808HesUkyt"
      },
      "source": [
        "<hr>\n",
        "Create new features based on the elements in the test basket:\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWBLv0LaUkyu"
      },
      "source": [
        "# List with basket elements\n",
        "# NOTE: We assume, that we have all these values in the basket label array\n",
        "#       We did NOT test this! Maybe test this to have more security...\n",
        "# TODO check whether all values are actually in the list\n",
        "test_basketElements = list(range(test_min_basket_value, test_max_basket_value+1))\n",
        "\n",
        "# Data frame with columns: 'b_0 | b_1 | ...' for each of our basket elements\n",
        "test_one_hot_basket = pd.DataFrame([], columns=[f'b_{test_basketElement}' for test_basketElement in test_basketElements])\n",
        "\n",
        "'''\n",
        "Do the one hot encoding for the basket feature.\n",
        "Actually just:\n",
        "    1. Check for the current basket, whether the element is present\n",
        "    2. If present, set the encoding bit\n",
        "'''\n",
        "for test_basketElement in test_basketElements:\n",
        "      test_one_hot_basket[f'b_{test_basketElement}'] = test_cleaned['basket'].apply(lambda x: x.count(str(test_basketElement)))\n",
        "\n",
        "test_one_hot_basket.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lva-wIb0Ukyu"
      },
      "source": [
        "#### 10.4 Concatenate it back into the original dataframe\n",
        "\n",
        "> Use pandas build in function\n",
        "\n",
        "1. Concatenate\n",
        "2. Clean up no more needed features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YmK_N30Ukyu"
      },
      "source": [
        "test_encoded = pd.concat([test_cleaned, test_one_hot_customerType, test_one_hot_basket], axis=1)\n",
        "\n",
        "# We'll keep basket, as it'll probably be helpful for the feature engineering, \n",
        "# We'll only convert it to an int list(from string) for better handling\n",
        "test_encoded['basket'] = [getIntListFromStringList(basket) for basket in test_cleaned.basket]\n",
        "\n",
        "# Clean up: Drop customerType as it is no longer needed\n",
        "test_encoded = test_encoded.drop(columns=['customerType'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJusHeeoUkyu"
      },
      "source": [
        "### 11. Test Datenattribute eliminieren\n",
        "\n",
        "> Test Datenattribute die nicht mit Zielvariable korrelieren entfernen\n",
        "\n",
        "Zu entfernen:\n",
        "    \n",
        "1. `transactionId`    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM8RUikuUkyv"
      },
      "source": [
        "# TODO better naming to dataframes\n",
        "test_encoded = test_encoded.drop(columns=['transactionId'])\n",
        "test_encoded.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6BRoskzUkyv"
      },
      "source": [
        "### 11. Features hinzuf√ºgen\n",
        "\n",
        "> Add all features from the feauture engineering part to the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCXDY-DbUkyv"
      },
      "source": [
        "def all_same(items):\n",
        "    return all(x == items[0] for x in items)\n",
        "\n",
        "test_encoded['same'] = test_encoded.basket.map(lambda x: 1 if all_same(x)  else 0)\n",
        "\n",
        "# ---\n",
        "test_f_eng_basket = list(test_encoded.basket) # basket shortcut\n",
        "\n",
        "test_encoded['maxCount'] = [round(test_encoded.totalAmount.iloc[i]/sum(basket), 2) for (i, basket) in enumerate(test_f_eng_basket) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MHvwASOUkyv"
      },
      "source": [
        "### 12. Skalieren Sie die Test Features mit einem StandardScaler.\n",
        "\n",
        "> Use sklearn scaler\n",
        "\n",
        "1. Drop target feature\n",
        "2. scale the x results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZiimISYUkyv"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Backup for the very end\n",
        "test_backup = test_encoded\n",
        "\n",
        "# Drop basket feature after using it in the feature eng. phase\n",
        "test_encoded = test_encoded.drop(columns=['basket'])\n",
        "# Drop our target\n",
        "x_test = test_encoded.drop(columns=['returnLabel'])\n",
        "\n",
        "# Our x/y values\n",
        "X_test = scaler.fit_transform(x_test)\n",
        "y_test = test_encoded['returnLabel'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jywY1TUkyv"
      },
      "source": [
        "### 13. Machen Sie eine Vorhersage auf den Testdaten mit allen drei Modellen und den jeweils besten Hyperparametern aus der Cross Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BtOO1qhUkyv"
      },
      "source": [
        "#### 13.1 Vorhersage auf Logistische Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0C2Vu6kUkyw"
      },
      "source": [
        "lr_prediction = lr_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O3-LIn9Ukyw"
      },
      "source": [
        "#### 13.2 Vorhersage auf Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKi7r2HUkyw"
      },
      "source": [
        "rf_prediction = rf_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SR54SIWUkyw"
      },
      "source": [
        "#### 13.3 Vorhersage auf Gradient Boosting Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpzOnQNZUkyw"
      },
      "source": [
        "gb_prediction = gb_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooAvizlZUkyw"
      },
      "source": [
        "### 14 Berechnen Sie f√ºr jedes der drei Modell Accuracy, Precision und Recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHLqVWaUUkyw"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVkr4f8NUkyx"
      },
      "source": [
        "#### 14.2 Accuracy, Precision & Recall f√ºr das logistische regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL7Aj1QRUkyx"
      },
      "source": [
        "# TODO Preeeettty sure something went wrong here...cause it's tooo god to be true ¬Ø\\_(„ÉÑ)_/¬Ø \n",
        "\n",
        "# TODO save old accuracy to compare\n",
        "# lr_accuracy_old = lr_accuracy\n",
        "lr_accuracy = accuracy_score(y_test, lr_prediction)\n",
        "print(f'Logistic regression accuracy: {lr_accuracy}')\n",
        "\n",
        "lr_precision = precision_score(y_test, lr_prediction)\n",
        "print(f'Logistic regression precision: {lr_precision}')\n",
        "\n",
        "lr_recall = recall_score(y_test, lr_prediction)\n",
        "print(f'Logistic regression recall: {lr_recall}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fe1wfDnUkyx"
      },
      "source": [
        "#### 14.2 Accuracy, Precision & Recall f√ºr das Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFRtPdmtUkyx"
      },
      "source": [
        "# TODO Preeeettty sure something went wrong here...cause it's tooo god to be true ¬Ø\\_(„ÉÑ)_/¬Ø \n",
        "\n",
        "# TODO save old accuracy to compare\n",
        "# rf_accuracy_old = rf_accuracy\n",
        "rf_accuracy = accuracy_score(y_test, rf_prediction)\n",
        "print(f'Random forest accuracy: {rf_accuracy}')\n",
        "\n",
        "rf_precision = precision_score(y_test, rf_prediction)\n",
        "print(f'Random forest precision: {rf_precision}')\n",
        "\n",
        "rf_recall = recall_score(y_test, rf_prediction)\n",
        "print(f'Random forest recall: {rf_recall}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CweblJKBUkyx"
      },
      "source": [
        "#### 14.3 Accuracy, Precision & Recall f√ºr das Gradient Boost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFv0n1f1Ukyy"
      },
      "source": [
        "# TODO Preeeettty sure something went wrong here...cause it's tooo god to be true ¬Ø\\_(„ÉÑ)_/¬Ø \n",
        "\n",
        "# TODO save old accuracy to compare\n",
        "# gb_accuracy_old = gb_accuracy\n",
        "gb_accuracy = accuracy_score(y_test, gb_prediction)\n",
        "print(f'Gradient Boost accuracy: {gb_accuracy}')\n",
        "\n",
        "gb_precision = precision_score(y_test, gb_prediction)\n",
        "print(f'Gradient Boost precision: {gb_precision}')\n",
        "\n",
        "gb_recall = recall_score(y_test, gb_prediction)\n",
        "print(f'Gradient Boost recall: {gb_recall}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DriJyvOMUkyy"
      },
      "source": [
        "#### 14.4 Accuracy summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWvdeF4Ukyy"
      },
      "source": [
        "calcPerc = lambda acc: round(acc * 100, 2)\n",
        "\n",
        "# print(f'Old accuracies:\\n\\n1. LR: {calcPerc(lr_accuracy_old)} %\\n2. RF: {calcPerc(rf_accuracy_old)} %\\n3. GB: {calcPerc(gb_accuracy_old)} %')\n",
        "\n",
        "# print(f'\\n---\\n')\n",
        "\n",
        "print(f'New accuracies:\\n\\n1. LR: {calcPerc(lr_accuracy)} %\\n2. RF: {calcPerc(rf_accuracy)} %\\n3. GB: {calcPerc(gb_accuracy)} %')\n",
        "\n",
        "# print(f'\\n---\\n')\n",
        "\n",
        "# print(f'The improvement/decrease of accuracy is:\\n\\n1. LR: {calcPerc((lr_accuracy- lr_accuracy_old))} %\\n2. RF: {calcPerc((rf_accuracy- rf_accuracy_old))} %\\n3. GB: {calcPerc((gb_accuracy- gb_accuracy_old))} %')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etVmj0jMUkyy"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## ANALYSIS üîç\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIc_Id5GUkyy"
      },
      "source": [
        "### 15 Untersuchen Sie wie viele Datenpunkte es in den Testdaten gibt, welche von allen drei Modellen falsch klassifiziert wurden:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETbskYkPUkyy"
      },
      "source": [
        "#### 15.1 Bestimmen Sie **f√ºr jedes der drei Modelle** die **Indizes** der **Testdatenpunkte** auf welchen das **jeweilige Modell falsch klassifiziert hat**.\n",
        "\n",
        "> Get the indices for of the wrong gessed data points: Process similar to prediction process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYG-vvkZUkyz"
      },
      "source": [
        "# Helper function to find wrong predicted test data pointes(See docstring)\n",
        "\n",
        "def getWrongClassfiedPredictions(input, predictions, labels):\n",
        "    \"\"\"\n",
        "    Takes in the input values to predict on,\n",
        "    the predictions made by the model\n",
        "    and the right labels to compare the predictions on.\n",
        "    \n",
        "    Returns a set with indices corresponding to the test datapoints,\n",
        "    which the model guessed wrong\n",
        "    \"\"\"\n",
        "    \n",
        "    wrong_predictions = set()\n",
        "    i = 0\n",
        "    for input, prediction, label in zip(input, predictions, labels):\n",
        "        if prediction != label:\n",
        "            wrong_predictions.add(i)\n",
        "        i += 1\n",
        "    return wrong_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDSpF0WMUkyz"
      },
      "source": [
        "#### 15.1.1 Falsch klassifizierte Testdatenpunkte des Logistische Regression Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geOVhIDmUkyz"
      },
      "source": [
        "lr_wrong_predictions = getWrongClassfiedPredictions(X_test, lr_prediction, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvKo-TLkUkyz"
      },
      "source": [
        "#### 15.1.2 Falsch klassifizierte Testdatenpunkte des Random forest Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1Ct4rLNUkyz"
      },
      "source": [
        "rf_wrong_predictions = getWrongClassfiedPredictions(X_test, rf_prediction, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spV3Gfr5Ukyz"
      },
      "source": [
        "#### 15.1.1 Falsch klassifizierte Testdatenpunkte des Gradient boost Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50mlH6ISUky0"
      },
      "source": [
        "clf_wrong_predictions = getWrongClassfiedPredictions(X_test, gb_prediction, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bdQpx9uUky0"
      },
      "source": [
        "#### 15.2 Nutzen Sie die set-Klasse in Python um die Anzahl an Datenpunkten zu bestimmen, welche von allen drei Modellen falsch klassifiziert wurden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wze73NSKUky0",
        "outputId": "9904a1be-9513-4c24-c905-4d0f1c58b885"
      },
      "source": [
        "allWrongDataPoints = lr_wrong_predictions & rf_wrong_predictions & clf_wrong_predictions\n",
        "\n",
        "# TODO use this as metric to improve model -> Bring number down!\n",
        "print(f'{len(allWrongDataPoints)} values found wrong categorized in common by all models')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "395 values found wrong categorized in common by all models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R7bIPHuUky0",
        "outputId": "47790792-d367-4ba0-c5c1-4918cb4a6448"
      },
      "source": [
        "# TODO find better pattern & use this \n",
        "\n",
        "# TODO use this as metric to improve model -> Search patterns and feature engineer better model\n",
        "\n",
        "# Check out missing baskets\n",
        "[print(test_backup['basket'].iloc[index]) for index in allWrongDataPoints]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 1, 1, 4, 3]\n",
            "[4]\n",
            "[3]\n",
            "[1, 4, 0, 4, 3, 3]\n",
            "[4, 2, 4, 4, 4, 0]\n",
            "[3, 2, 1, 0, 4]\n",
            "[2]\n",
            "[4, 0, 3, 1, 4, 1, 4]\n",
            "[3]\n",
            "[1]\n",
            "[1]\n",
            "[4]\n",
            "[2, 2, 4]\n",
            "[2, 3, 4]\n",
            "[0]\n",
            "[0, 4, 3]\n",
            "[2, 4, 0, 3, 4]\n",
            "[1, 3, 1, 2, 4, 3]\n",
            "[4]\n",
            "[4, 1, 4, 3, 0, 2, 2]\n",
            "[3]\n",
            "[1, 4, 0]\n",
            "[4, 4, 4, 3, 2]\n",
            "[2, 0, 4]\n",
            "[1, 2, 4, 2]\n",
            "[3]\n",
            "[4, 4, 4, 0, 4]\n",
            "[3, 2, 4, 2, 4]\n",
            "[3, 3, 0]\n",
            "[1, 4, 2, 2]\n",
            "[2, 2, 3, 4, 3, 2]\n",
            "[3, 0]\n",
            "[3]\n",
            "[1, 4, 3, 1]\n",
            "[3, 0, 1, 4]\n",
            "[1]\n",
            "[4]\n",
            "[2]\n",
            "[4]\n",
            "[4, 1]\n",
            "[1]\n",
            "[4, 1, 3, 0]\n",
            "[1]\n",
            "[4]\n",
            "[0]\n",
            "[3]\n",
            "[4]\n",
            "[1, 3, 0]\n",
            "[3]\n",
            "[4]\n",
            "[3, 2, 3, 3]\n",
            "[1, 0, 2, 3, 3, 0, 4, 3]\n",
            "[3]\n",
            "[2, 0, 4, 4, 0]\n",
            "[2, 4, 1, 0, 4, 0, 4]\n",
            "[1, 4]\n",
            "[4, 1, 4, 0]\n",
            "[1, 3, 0, 3, 1, 4, 4, 4, 3]\n",
            "[4]\n",
            "[4, 1, 2, 2, 3]\n",
            "[2, 4, 4, 2, 0, 3]\n",
            "[4, 1]\n",
            "[4]\n",
            "[3, 3, 3, 2, 3]\n",
            "[1, 2, 0, 2]\n",
            "[3, 3, 3, 2, 2]\n",
            "[4, 0, 4, 4, 1]\n",
            "[3, 1, 0, 1, 0, 0]\n",
            "[3, 1, 3, 1, 3]\n",
            "[3, 0, 3]\n",
            "[0, 4, 4, 1, 3, 0]\n",
            "[3, 0]\n",
            "[4, 3, 4, 4]\n",
            "[4, 0]\n",
            "[4, 1]\n",
            "[3, 4, 3, 2, 1, 0]\n",
            "[4, 2, 4, 3, 4, 4]\n",
            "[3, 2]\n",
            "[4]\n",
            "[2, 3, 0]\n",
            "[4]\n",
            "[0, 4, 3, 4, 4]\n",
            "[0]\n",
            "[1]\n",
            "[2]\n",
            "[4]\n",
            "[2, 3, 3, 1, 3]\n",
            "[3]\n",
            "[4]\n",
            "[4, 3, 1, 0, 2]\n",
            "[2, 3, 1, 2, 4, 0, 4, 1, 2]\n",
            "[3]\n",
            "[0]\n",
            "[4, 2, 3, 2, 2, 3, 3, 3]\n",
            "[4, 2, 1, 2, 2, 4, 4, 4, 3, 2, 1]\n",
            "[1]\n",
            "[1, 3, 0, 4, 4, 3]\n",
            "[1, 0, 4, 3, 1]\n",
            "[1, 4, 4, 4]\n",
            "[2]\n",
            "[4, 3, 1, 0, 1, 4, 2]\n",
            "[1, 3, 4]\n",
            "[4]\n",
            "[1, 4]\n",
            "[0, 3, 3]\n",
            "[1]\n",
            "[3, 2, 0, 0, 4, 4, 1]\n",
            "[0, 3, 4, 2]\n",
            "[3]\n",
            "[0, 2]\n",
            "[1, 0, 4, 2]\n",
            "[3, 4, 2, 3, 1, 4, 4]\n",
            "[1, 3]\n",
            "[0, 2, 0, 3]\n",
            "[3, 1, 3, 4, 3, 1, 0]\n",
            "[3, 2, 4]\n",
            "[4, 4, 3, 1, 2, 2, 4]\n",
            "[4, 4, 2, 4, 0]\n",
            "[3]\n",
            "[3, 0]\n",
            "[4]\n",
            "[4]\n",
            "[1]\n",
            "[2, 4, 4, 4]\n",
            "[1, 2, 1]\n",
            "[2, 3, 1, 3, 4, 0, 2]\n",
            "[2, 3, 4, 1, 2]\n",
            "[1, 3, 4, 4, 4, 1, 4, 3, 3, 2]\n",
            "[4]\n",
            "[3]\n",
            "[1, 0, 3, 1, 4, 2, 4, 3]\n",
            "[0]\n",
            "[3]\n",
            "[2, 2, 1, 3, 4, 4, 4, 3, 4]\n",
            "[2, 3]\n",
            "[4, 1, 4, 0, 4]\n",
            "[4, 2, 4, 4, 4]\n",
            "[3]\n",
            "[4, 4, 0, 1]\n",
            "[0]\n",
            "[4, 3, 4, 1, 3, 4, 3, 4]\n",
            "[1, 4, 0, 4, 4]\n",
            "[1]\n",
            "[4]\n",
            "[3]\n",
            "[3, 0, 0]\n",
            "[0, 3, 2, 2]\n",
            "[1]\n",
            "[4, 0]\n",
            "[3]\n",
            "[2, 3, 4, 2, 3, 3]\n",
            "[4]\n",
            "[4, 3, 4, 0, 4]\n",
            "[4]\n",
            "[4]\n",
            "[4]\n",
            "[4]\n",
            "[2, 4, 4, 4]\n",
            "[3, 3, 3, 1]\n",
            "[0, 4, 0, 4, 4]\n",
            "[4]\n",
            "[2, 3, 4, 2, 4, 2]\n",
            "[1]\n",
            "[4, 4, 1]\n",
            "[1]\n",
            "[1, 0, 3, 2]\n",
            "[4]\n",
            "[4]\n",
            "[4, 2, 1, 4, 2]\n",
            "[3, 2, 4]\n",
            "[4, 3, 3, 1, 2, 3, 4, 1, 4]\n",
            "[1, 1, 3, 4, 4, 4]\n",
            "[4, 4, 4, 2, 4, 0, 2]\n",
            "[2, 3]\n",
            "[1, 0, 3]\n",
            "[3]\n",
            "[4]\n",
            "[0]\n",
            "[0, 2]\n",
            "[0, 1]\n",
            "[0]\n",
            "[2, 4, 4, 1, 3, 0]\n",
            "[4, 4, 0, 4, 4]\n",
            "[3, 4, 4, 3, 0]\n",
            "[4]\n",
            "[1, 3, 0, 3, 2, 0, 3, 4]\n",
            "[4, 4, 4]\n",
            "[2]\n",
            "[4, 2, 2, 1, 1, 0]\n",
            "[4, 0, 4, 4, 2]\n",
            "[3, 3, 3, 3, 1, 2, 4, 4, 3, 4]\n",
            "[0, 2]\n",
            "[0, 2, 4, 4]\n",
            "[3]\n",
            "[0]\n",
            "[3, 4, 1]\n",
            "[4, 4, 4, 0, 3]\n",
            "[3]\n",
            "[1]\n",
            "[4, 1]\n",
            "[1]\n",
            "[3, 3, 1, 0, 4, 3, 4, 0, 3, 3, 2]\n",
            "[3, 3, 1, 1, 0, 4]\n",
            "[4]\n",
            "[1]\n",
            "[4]\n",
            "[3, 0]\n",
            "[1, 4, 4, 2]\n",
            "[1, 4, 0, 3, 3, 2]\n",
            "[2, 1, 3, 3, 0, 1, 4, 3, 3, 2, 4]\n",
            "[3, 3, 1, 3, 3]\n",
            "[4]\n",
            "[4, 3, 1, 0]\n",
            "[1]\n",
            "[1]\n",
            "[3, 3, 2, 2, 2, 3]\n",
            "[0, 2, 4, 3, 3, 1]\n",
            "[3, 3, 1, 2, 1, 4, 0]\n",
            "[4, 3]\n",
            "[4]\n",
            "[3, 3, 0, 1, 4]\n",
            "[4, 3]\n",
            "[0, 4]\n",
            "[1, 1, 3, 4]\n",
            "[0]\n",
            "[4]\n",
            "[3, 4, 1, 1, 3, 3, 2]\n",
            "[4, 2]\n",
            "[1, 1, 3, 2, 3, 4, 4]\n",
            "[3]\n",
            "[0, 4, 3, 0]\n",
            "[1, 3, 2, 3, 4]\n",
            "[0, 2, 4, 0, 4, 3]\n",
            "[1, 3, 3]\n",
            "[3]\n",
            "[4]\n",
            "[4]\n",
            "[4, 3, 4, 2, 3, 2]\n",
            "[3, 0, 4]\n",
            "[4]\n",
            "[0, 1, 3]\n",
            "[3]\n",
            "[2]\n",
            "[3, 0, 3, 0, 4, 2]\n",
            "[3, 4, 2, 4, 3, 3]\n",
            "[1, 4, 1, 2, 4, 2]\n",
            "[2, 3, 3, 0, 4, 0]\n",
            "[3]\n",
            "[4]\n",
            "[3, 4, 2, 0]\n",
            "[3, 4, 3, 4, 2, 4, 3]\n",
            "[3, 1]\n",
            "[0, 0, 4, 2, 0, 4, 3, 2]\n",
            "[4]\n",
            "[0, 1, 4]\n",
            "[1, 2]\n",
            "[3]\n",
            "[4]\n",
            "[3]\n",
            "[4, 3, 4, 0, 0]\n",
            "[3, 1]\n",
            "[4, 4, 4, 1]\n",
            "[4]\n",
            "[1, 1, 4, 4]\n",
            "[2]\n",
            "[4]\n",
            "[1, 4, 1, 2, 3, 4]\n",
            "[4]\n",
            "[3, 3]\n",
            "[3, 1, 2, 1, 0, 3]\n",
            "[3, 2]\n",
            "[0, 4, 4, 4]\n",
            "[4, 2, 0, 3, 3]\n",
            "[0]\n",
            "[3, 3]\n",
            "[4, 1, 2]\n",
            "[1]\n",
            "[2, 4]\n",
            "[3, 2]\n",
            "[4, 2, 3]\n",
            "[3, 0, 4]\n",
            "[3, 2, 3]\n",
            "[1, 4, 3, 0]\n",
            "[2]\n",
            "[2, 4, 0, 4, 0, 0]\n",
            "[4, 3, 0, 3]\n",
            "[3, 4, 4, 3, 3, 4]\n",
            "[2, 2, 0, 4, 3, 3, 3, 2]\n",
            "[0, 4]\n",
            "[3]\n",
            "[2, 1, 2, 1]\n",
            "[2, 4, 3]\n",
            "[4, 1]\n",
            "[4, 1, 0]\n",
            "[3, 3, 2]\n",
            "[0]\n",
            "[1]\n",
            "[4]\n",
            "[4, 4, 4, 2]\n",
            "[2, 3, 4]\n",
            "[4, 3, 4, 4]\n",
            "[3, 4, 1, 0, 0]\n",
            "[4, 2, 4, 1, 4, 4, 4, 3, 2]\n",
            "[3, 4, 2, 3, 2]\n",
            "[3, 3]\n",
            "[2, 2, 3]\n",
            "[0, 4, 0, 4, 2, 3]\n",
            "[0, 3]\n",
            "[3, 4, 4, 4, 4, 3]\n",
            "[4, 3, 2, 4, 0, 4, 2, 4, 4, 3]\n",
            "[3, 3, 2, 4, 0]\n",
            "[3, 1, 1, 1, 3]\n",
            "[2, 2, 4, 1, 4, 0]\n",
            "[4, 4, 3, 2, 4]\n",
            "[0]\n",
            "[0, 4, 1, 4, 1, 4, 0]\n",
            "[1, 4, 0, 4, 4, 4]\n",
            "[4]\n",
            "[3]\n",
            "[3, 4, 3, 1, 2, 0, 3, 3, 4]\n",
            "[2]\n",
            "[4, 0, 3, 3, 1, 4, 0]\n",
            "[1, 4, 0, 0, 3, 1]\n",
            "[1, 4]\n",
            "[3, 4, 3, 2, 4, 3]\n",
            "[1]\n",
            "[2, 2, 2, 4, 3, 3]\n",
            "[4, 4, 3, 4]\n",
            "[0, 0]\n",
            "[0, 4, 0, 1, 2, 0, 0, 4]\n",
            "[4, 3, 2, 3]\n",
            "[4, 0, 0, 4, 2, 4, 3]\n",
            "[0, 4, 0, 0, 3]\n",
            "[2, 4, 3]\n",
            "[2, 1, 3, 4, 3]\n",
            "[3]\n",
            "[4, 4, 3, 3]\n",
            "[3, 2, 1, 4]\n",
            "[3]\n",
            "[3, 4]\n",
            "[1, 3, 4, 2]\n",
            "[4]\n",
            "[4, 0, 1, 0]\n",
            "[0, 4, 3, 2, 3, 4, 0, 4]\n",
            "[3, 1, 0, 4, 2]\n",
            "[4]\n",
            "[3, 4, 4, 2, 1]\n",
            "[1, 4]\n",
            "[4, 4, 4, 0, 3, 2]\n",
            "[1, 0, 4, 3]\n",
            "[4]\n",
            "[0]\n",
            "[4]\n",
            "[3]\n",
            "[0, 2, 3, 4]\n",
            "[4, 4, 2, 3, 3, 1, 4, 3]\n",
            "[1, 4, 0, 4]\n",
            "[3]\n",
            "[1, 4, 4, 4, 2]\n",
            "[3, 4, 4, 4]\n",
            "[0]\n",
            "[1, 0, 1, 1, 4, 3]\n",
            "[4]\n",
            "[3, 4, 0, 1, 0]\n",
            "[4, 3, 4, 1, 3, 4, 0]\n",
            "[4, 2]\n",
            "[0, 4, 1]\n",
            "[4, 3, 0]\n",
            "[4]\n",
            "[4]\n",
            "[4]\n",
            "[0, 3, 4]\n",
            "[4, 1]\n",
            "[4, 2]\n",
            "[2]\n",
            "[4, 3, 2]\n",
            "[3, 3, 1, 0, 0, 3, 4]\n",
            "[3, 4, 0, 1]\n",
            "[4, 1, 1, 0, 4]\n",
            "[1, 4]\n",
            "[1, 3, 4, 0, 2, 3]\n",
            "[3, 2, 1, 2, 4]\n",
            "[3, 4, 2, 0]\n",
            "[2]\n",
            "[1, 4, 1]\n",
            "[0, 3, 3, 3]\n",
            "[4]\n",
            "[1, 2, 4, 4, 0, 3, 1]\n",
            "[4]\n",
            "[2, 4, 4, 4]\n",
            "[0, 3, 3, 3, 2, 3, 1, 4]\n",
            "[0, 1, 3, 3]\n",
            "[4, 4, 4, 2, 3, 3]\n",
            "[4, 0, 0]\n",
            "[3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io0vvOGtUky0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}